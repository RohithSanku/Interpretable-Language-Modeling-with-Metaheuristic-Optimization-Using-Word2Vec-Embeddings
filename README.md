This repository contains the implementation of a novel approach to language modeling that enhances interpretability and reduces computational costs by utilizing metaheuristic optimization. The method leverages pre-trained word2vec embeddings to vectorize words and predicts word embeddings through non-linear functions of preceding word embeddings. Optimization is performed using differential evolution to maximize cosine similarity and minimize Euclidean distance between predicted and observed embeddings. This approach aims to improve the trustworthiness, technical robustness, and fairness of language models across various applications.
